{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "number_of_classes_M = 2\n",
    "number_of_features_F = 5\n",
    "initial_weights = np.random.uniform(low=-1, high=1, size = (number_of_classes_M, number_of_features_F))\n",
    "N = 1000\n",
    "meanOne = 0.1\n",
    "meanTwo = 0\n",
    "stDiv = 1\n",
    "gdVectorOne = np.random.normal(meanOne, stDiv, size = (N//2, number_of_features_F))\n",
    "gdVectorTwo = np.random.normal(meanTwo, stDiv, size = (N//2, number_of_features_F))\n",
    "gdVector = (np.concatenate((gdVectorOne, gdVectorTwo)))\n",
    "oneHotOne = np.hstack(((np.zeros(N//2)).reshape(N//2,1), (np.ones(N//2)).reshape(N//2,1)))\n",
    "oneHotTwo = np.hstack(((np.ones(N//2)).reshape(N//2,1), (np.zeros(N//2)).reshape(N//2,1)))\n",
    "oneHotEn = np.vstack((oneHotOne, oneHotTwo))\n",
    "random = np.random.permutation(N)\n",
    "gdVectorMixed = gdVector[random]\n",
    "oneHotEnMixed = oneHotEn[random]\n",
    "oneHotEnOne = oneHotEnMixed[:,0].reshape(1000,1)\n",
    "oneHotEnTwo = oneHotEnMixed[:,1].reshape(1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "[[ 0.17072022 -0.10492489  0.5251751  -0.93961923  0.83756163]\n",
      " [-0.41675604  0.23002063  0.22041237 -0.67920973  0.23054583]]\n",
      "[[ 0.16468738 -0.0996202   0.5016424  -0.89816419  0.7978607 ]\n",
      " [-0.39290351  0.22312115  0.21320659 -0.64418131  0.22017766]]\n"
     ]
    }
   ],
   "source": [
    "for n in range (50):\n",
    "    eW = np.dot(gdVectorMixed, initial_weights.T)\n",
    "    eWOne = eW[:,0].reshape(1000,1)\n",
    "    eWTwo = eW[:,1].reshape(1000,1)\n",
    "    eWOneCalc = 0.5 * ((eWOne - oneHotEnOne) ** 2)\n",
    "    eWTwoCalc = 0.5 * ((eWTwo - oneHotEnTwo) ** 2)\n",
    "    enW = eWOneCalc + eWTwoCalc\n",
    "    gradient = np.dot(gdVectorMixed.T,(eW - oneHotEnMixed))\n",
    "    print(gradient.shape)\n",
    "    stepSize = .00005\n",
    "\n",
    "    wPrime = initial_weights - (.00005 * gradient).T\n",
    "\n",
    "print(initial_weights)\n",
    "print(wPrime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "number_of_feature = 13\n",
    "number_of_units_in_hidden_layer = 100\n",
    "#### load the BOSTON regression dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=113)\n",
    "#### pre-process the data\n",
    "x_train -= np.mean(x_train)\n",
    "x_train /= np.std(x_train)\n",
    "x_test -= np.mean(x_test)\n",
    "x_test /= np.std(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (571226105.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[127], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    (units = 1 for regression)\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "NN_regression_model = tf.keras.Sequential()\n",
    "hidden_layer_1 = layers.Dense(units=number_of_units_in_hidden_layer,activation='relu', input_shape= (num_features,)) # define layer\n",
    "NN_regression_model.add(hidden_layer_1) # add layer\n",
    "hidden_layer_2 = layers.Dense(units=number_of_units_in_hidden_layer,activation='relu') # define layer\n",
    "NN_regression_model.add(hidden_layer_2) # add layer\n",
    "output_layer = layers.Dense(units=1, activation=None) # define layer\n",
    "(units = 1 for regression)\n",
    "NN_regression_model.add(output_layer) # add layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
